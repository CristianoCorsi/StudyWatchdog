# ğŸ• StudyWatchdog

> Un assistente AI locale che ti tiene d'occhio mentre studi â€” e ti richiama se ti distrai troppo.

**StudyWatchdog** usa la webcam e modelli AI locali per capire se stai studiando o meno. Se smetti per troppo tempo, ti avvisa con suoni, TTS, o notifiche.

## ğŸ¯ Goal
Un progetto fun/didattico per esplorare vision AI locale, non un prodotto commerciale.

## ğŸ–¥ï¸ Hardware Target
- GPU: NVIDIA RTX A2000 8GB (Laptop)
- CPU: Intel i7-12850HX
- RAM: 32GB
- **Tutto gira in locale** â€” nessuna API cloud

## ğŸ—ï¸ Architecture

```
Camera â†’ Detector (AI) â†’ Decision Engine â†’ Alerter
              â†‘                    â†‘
              â””â”€â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Loop principale:
1. Cattura frame dalla webcam (ogni 5s configurabili)
2. Il detector classifica: `studying` | `not_studying` | `absent`
3. Il decision engine traccia lo stato nel tempo
4. L'alerter si attiva dopo un timeout di distrazione

## ğŸ§  Opzioni per la Detection

### Opzione A: Small Vision-Language Model (VLM) â€” â­ Consigliata
**Modello: [moondream2](https://github.com/vikhyat/moondream)** (~2B parametri)

- **Pro**: Molto flessibile â€” basta chiedere "is this person studying?" in linguaggio naturale
- **Pro**: Capisce il contesto visivo (libri, laptop, postura, ecc.)
- **Pro**: Sta comodamente in 8GB VRAM (anche in fp16)
- **Pro**: PuÃ² dare risposte articolate, non solo classificazione binaria
- **Con**: PiÃ¹ lento (~1-3s per frame su A2000), ma accettabile per analisi ogni 5s
- **Con**: PuÃ² essere inconsistente su edge cases

**Come funziona**: Dai un'immagine al modello + un prompt tipo "Describe what the person is doing. Are they studying or distracted?" e il modello risponde in testo. Si parsa la risposta per determinare lo stato.

### Opzione B: MediaPipe Pose Estimation + Regole
- **Pro**: Ultra-veloce (<50ms), leggero, nessuna GPU necessaria
- **Pro**: Deterministico e prevedibile
- **Con**: Molto limitato â€” puÃ² dire "persona seduta al desk" ma non se sta studiando vs scrollando Instagram
- **Con**: Richiede regole manuali (fragile)

### Opzione C: YOLO Object Detection
- **Pro**: Veloce, affidabile per detection di oggetti (libri, laptop, telefono)
- **Con**: Rileva oggetti, non attivitÃ  â€” un libro aperto non vuol dire che stai leggendo

### Opzione D: Classificatore Custom (fine-tuned)
- **Pro**: Potenzialmente molto accurato
- **Con**: Richiede raccolta dati e training â€” troppo effort per un progetto fun

### ğŸ† Strategia Raccomandata: Partire con Moondream2

**PerchÃ©**: Ãˆ il miglior rapporto effort/risultato. Con un singolo prompt puoi ottenere una classificazione ragionevole senza dover definire regole manuali o raccogliere dataset. Se non funziona bene, si puÃ² sempre aggiungere MediaPipe come fallback leggero.

**Piano B**: Se moondream2 Ã¨ troppo lento o impreciso, si puÃ² provare il modello 0.5B o passare a un approccio YOLO + regole euristiche.

## ğŸš€ Quick Start

```bash
# Clona e entra nella directory
cd StudyWatchdog

# Installa le dipendenze
uv sync

# Avvia
uv run studywatchdog

# Test
uv run pytest

# Lint & Format
uv run ruff check src/
uv run ruff format src/
```

## ğŸ“¦ Tech Stack
- **Python 3.12+**
- **uv** â€” package manager
- **OpenCV** â€” webcam
- **PyTorch + Transformers** â€” AI models
- **Ruff** â€” linting/formatting
- **pytest** â€” testing

## ğŸ—ºï¸ Roadmap

### Phase 1: Foundation
- [ ] Webcam capture funzionante (preview live)
- [ ] Struttura progetto e config
- [ ] Entry point CLI

### Phase 2: Detection
- [ ] Integrazione moondream2
- [ ] Classificazione base "studia vs non studia"
- [ ] Benchmark performance su hardware target

### Phase 3: Alerts
- [ ] Riproduzione suono quando ti distrai
- [ ] Timeout e cooldown configurabili
- [ ] TTS base

### Phase 4: Polish
- [ ] System tray / mini GUI
- [ ] Statistiche sessione (% tempo studio)
- [ ] Fine-tune della detection
- [ ] Sistema di escalation degli alert

## ğŸ“„ License
MIT
