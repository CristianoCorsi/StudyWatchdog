# ğŸ• StudyWatchdog

> A local AI assistant that watches you while you study â€” and if you get distracted for too long... it rickrolls you. ğŸµ

**StudyWatchdog** uses your webcam and a local vision model (**SigLIP**) to classify in real-time whether you're studying or not. If you stop for too long, it rickrolls you until you resume.

## ğŸ¯ Goal
A fun/educational project to explore local vision AI, not a commercial product.

## ğŸ–¥ï¸ Hardware Target
- GPU: NVIDIA RTX A2000 8GB (Laptop)
- CPU: Intel i7-12850HX
- RAM: 32GB
- **Everything runs locally** â€” no cloud APIs

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Camera   â”‚â”€â”€â”€â–¶â”‚  Detector    â”‚â”€â”€â”€â–¶â”‚ Decision Engine â”‚â”€â”€â”€â–¶â”‚   Alerter     â”‚
â”‚ (OpenCV)  â”‚    â”‚  (SigLIP)    â”‚    â”‚ (EMA + FSM)     â”‚    â”‚ (Rickroll ğŸµ) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚                      â”‚
                       â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
                       â””â”€â”€â”€â”€â”€â–¶â”‚ Config â”‚â—€â”€â”€â”€â”€â”€â”˜
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Main Loop
1. **Camera** captures a frame every N seconds (default: 3s)
2. **Detector (SigLIP)** computes image similarity vs text candidates â†’ numerical score 0.0-1.0
3. **Decision Engine** applies EMA (Exponential Moving Average) on scores to smooth results, then an FSM (Finite State Machine) decides state transitions
4. **Alerter** starts the rickroll when distraction timeout is exceeded, stops it when studying resumes

### Why SigLIP and not an LLM/VLM?

| Criterion | SigLIP (zero-shot classification) | VLM (moondream, LLaVA...) |
|---|---|---|
| **Output** | Numerical score 0.0-1.0, direct | Free text to parse (fragile!) |
| **Speed** | ~20-50ms per frame on GPU | ~1-3s per frame |
| **Size** | ~0.2B params, ~400MB | ~2B+ params, ~4GB+ |
| **Determinism** | Same input â†’ same output | Can vary on each run |
| **Robustness** | No parsing, no hallucination | The model can "invent" |
| **Thresholds** | Numerically configurable | Need to interpret text |
| **VRAM** | ~1GB | ~3-4GB |

**SigLIP** is a contrastive model (like CLIP, but better) that compares an image with text descriptions and returns a **numerical similarity score** for each. No text to generate, no parsing, no hallucinations â€” just numbers.

### How Detection Works

```python
# Detector pseudocode
texts = [
    "a person studying, reading a book, or working focused at a desk",
    "a person distracted, looking at phone, not paying attention",
    "an empty desk, no person visible",
]
scores = siglip(image, texts)  # â†’ [0.82, 0.15, 0.03]
# Highest wins â†’ "studying" with confidence 0.82
```

Text prompts are **configurable**: if classification isn't good on certain edge cases, just modify the text descriptions without touching code or retraining.

### Decision Engine: Temporal Tolerance

A single frame isn't enough to decide â€” the system uses:

1. **EMA (Exponential Moving Average)** on confidence scores to smooth noise and flicker:
   - $\text{EMA}_t = \alpha \cdot \text{score}_t + (1 - \alpha) \cdot \text{EMA}_{t-1}$
   - With $\alpha = 0.3$ (configurable) â†’ individual spikes are attenuated

2. **FSM (Finite State Machine)** with 3 states and time-based transitions:
   ```
   STUDYING â”€â”€(EMA < threshold for N seconds)â”€â”€â–¶ DISTRACTED
   DISTRACTED â”€â”€(EMA > threshold for M seconds)â”€â”€â–¶ STUDYING
   DISTRACTED â”€â”€(timeout exceeded)â”€â”€â–¶ ALERT_ACTIVE (rickroll!)
   ALERT_ACTIVE â”€â”€(EMA > threshold)â”€â”€â–¶ STUDYING (rickroll stop)
   ```

3. **Configurable parameters**:
   - `distraction_timeout`: seconds before alert (default: 30s)
   - `recovery_time`: seconds of studying to exit distracted state (default: 5s)
   - `studying_threshold`: EMA threshold for "is studying" (default: 0.5)
   - `ema_alpha`: weight of latest frame in EMA (default: 0.3)

### ğŸµ The Rickroll

When the decision engine decides you've been distracted too long:
- Plays **"Never Gonna Give You Up"** by Rick Astley
- Playback is **interruptible**: as soon as you resume studying, it stops
- If you get distracted again, it restarts (with configurable cooldown to avoid being too aggressive)
- Future: escalation (first a gentle nudge, then full rickroll, then TTS roast)

## ğŸš€ Quick Start

```bash
# Install dependencies
uv sync

# Start
uv run studywatchdog

# Test
uv run pytest

# Lint & Format
uv run ruff check src/
uv run ruff format src/
```

## ğŸ“¦ Tech Stack
- **Python 3.12+**
- **uv** â€” package manager
- **SigLIP** (`google/siglip-base-patch16-224`) â€” zero-shot image classification
- **OpenCV** â€” webcam capture
- **PyTorch + Transformers** â€” model runtime
- **pygame** â€” audio playback (rickroll!)
- **Ruff** â€” linting/formatting
- **pytest** â€” testing

## ğŸ—ºï¸ Roadmap

### Phase 1: Foundation âœ…
- [x] Project structure and config
- [x] CLI entry point
- [x] Camera capture working (live preview)

### Phase 2: Detection âœ…
- [x] SigLIP zero-shot classification integration
- [x] Decision engine with EMA + FSM
- [ ] Tuning text prompts and thresholds
- [ ] Performance benchmarking on target hardware

### Phase 3: Rickroll ğŸµ
- [ ] Download/include rickroll audio
- [x] Play/stop controlled by decision engine
- [x] Cooldown and anti-spam

### Phase 4: Polish âœ¨
- [ ] Data recording for calibration (user as test person)
- [ ] Session statistics (% study time)
- [ ] Alert escalation (nudge â†’ rickroll â†’ TTS roast)
- [ ] System tray / mini GUI

## ğŸ“„ License
MIT
