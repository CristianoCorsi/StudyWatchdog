# AGENTS.md ‚Äî Agent Guidelines for StudyWatchdog

This file provides guidelines for AI coding agents working on this project.

## üéØ Project Goal
Build a webcam-based AI monitor that detects if the user is studying and alerts them when they stop for too long. The system runs entirely locally on consumer hardware (NVIDIA RTX A2000 8GB, 32GB RAM).

## üß± Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Camera     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Detector    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Decision   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Alerter   ‚îÇ
‚îÇ  (OpenCV)    ‚îÇ     ‚îÇ  (AI Model)   ‚îÇ     ‚îÇ   Engine    ‚îÇ     ‚îÇ (Sound/TTS)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ                                         ‚îÇ
      ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    Config     ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Data Flow
1. **Camera** captures a frame every N seconds (configurable, default 5s)
2. **Detector** analyzes the frame and returns a classification: `studying` | `not_studying` | `absent`
3. **Decision Engine** (in main loop) tracks state over time ‚Äî a single frame of "not studying" is not enough to trigger an alert
4. **Alerter** fires when the distraction timeout is exceeded

## üìè Rules for Agents

### DO
- ‚úÖ Use `uv` for ALL package management (`uv add`, `uv run`)
- ‚úÖ Write type hints on all function signatures
- ‚úÖ Write docstrings (Google style) on all public functions
- ‚úÖ Keep modules focused ‚Äî one responsibility per file
- ‚úÖ Test with `pytest` (mock camera/audio in tests)
- ‚úÖ Use Ruff for linting and formatting
- ‚úÖ Prefer standard library when possible
- ‚úÖ Use `logging` module (not `print()`) for debug/info output
- ‚úÖ Handle errors gracefully with informative messages
- ‚úÖ Consider GPU memory constraints (8GB VRAM total)

### DON'T
- ‚ùå Use `pip install` ‚Äî always use `uv add`
- ‚ùå Use cloud APIs ‚Äî everything must run locally
- ‚ùå Add unnecessary dependencies
- ‚ùå Write overly complex abstractions for a fun project
- ‚ùå Load AI models eagerly at import time
- ‚ùå Block the main thread with synchronous model inference without a timeout
- ‚ùå Hardcode paths, thresholds, or model names ‚Äî use config
- ‚ùå Ignore the `src/` layout ‚Äî all source code lives in `src/studywatchdog/`
- ‚ùå Create new top-level Python files ‚Äî use the module structure

### When Implementing the Detector
1. Start with the simplest approach that works
2. The detector interface should be a **Protocol** so implementations are swappable
3. Every detector must implement: `detect(frame: np.ndarray) -> DetectionResult`
4. `DetectionResult` should include: `status` (enum), `confidence` (float), `details` (dict)
5. Log inference time for performance monitoring

### When Implementing Alerts
1. Start with simple sound playback (e.g., `playsound` or `pygame.mixer`)
2. TTS can be added later (e.g., `pyttsx3` or `edge-tts`)
3. Alerts should have configurable cooldown (don't spam the user)
4. Escalation is a nice-to-have: gentle nudge ‚Üí louder alert ‚Üí TTS roast

### When Modifying Config
1. Use a dataclass or Pydantic model
2. Support loading from a YAML/TOML file
3. All magic numbers must be in config, not scattered in code
4. Provide sensible defaults

## üß™ Testing Strategy
- **Unit tests**: Test detector logic with sample images, test alerter with mocked audio
- **Integration tests**: Test the main loop with a mocked camera
- **Manual testing**: Provide a CLI flag to use a video file instead of live camera

## üì¶ Key Dependencies (expected)
| Package | Purpose |
|---|---|
| `opencv-python` | Webcam capture and image processing |
| `torch` | ML model runtime |
| `transformers` | Hugging Face model loading |
| `Pillow` | Image conversion |
| `pydantic` | Configuration models |

Additional dependencies TBD based on chosen detection approach.

## üó∫Ô∏è Development Roadmap

### Phase 1: Foundation ‚úèÔ∏è
- [ ] Camera capture working (show live preview)
- [ ] Basic project structure and config
- [ ] CLI entry point

### Phase 2: Detection üß†
- [ ] Choose and integrate detection model
- [ ] Implement detector with Protocol interface
- [ ] Basic "studying vs not" classification
- [ ] Performance benchmarking on target hardware

### Phase 3: Alerts üîî
- [ ] Sound playback on distraction
- [ ] Configurable timeout and cooldown
- [ ] Basic TTS integration

### Phase 4: Polish ‚ú®
- [ ] Simple GUI or system tray integration
- [ ] Session statistics (% time studying)
- [ ] Fine-tune detection accuracy
- [ ] Alert escalation system
